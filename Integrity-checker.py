#!/usr/bin/env python3
"""
DATA INTEGRITY CHECKER
======================
–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∞—Ä—Ö–∏–≤–∞.
–°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã —Å –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–º–∏.
–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –ß–¢–û –∏–º–µ–Ω–Ω–æ –ø–æ—Ç–µ—Ä—è–ª–æ—Å—å –∏–ª–∏ –∏–∑–º–µ–Ω–∏–ª–æ—Å—å.
"""

import json
import os
import sys
from pathlib import Path
from collections import defaultdict
import argparse


class IntegrityChecker:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç—å –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
    
    def __init__(self, original_dir: str, processed_dir: str):
        self.original_dir = Path(original_dir)
        self.processed_dir = Path(processed_dir)
        self.report = defaultdict(dict)
        
    def check_json_conversations(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ JSON —Ñ–∞–π–ª–∞ —Å –¥–∏–∞–ª–æ–≥–∞–º–∏"""
        print("\n" + "="*70)
        print("–ü–†–û–í–ï–†–ö–ê CONVERSATIONS.JSON")
        print("="*70)
        
        # –ü–æ–∏—Å–∫ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
        original_json = None
        for root, dirs, files in os.walk(self.original_dir):
            for file in files:
                if file.lower() in ['conversations.json', 'chats.json']:
                    original_json = Path(root) / file
                    break
            if original_json:
                break
        
        if not original_json or not original_json.exists():
            print("‚ùå –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π conversations.json –ù–ï –ù–ê–ô–î–ï–ù")
            return False
        
        print(f"‚úÖ –ù–∞–π–¥–µ–Ω –æ—Ä–∏–≥–∏–Ω–∞–ª: {original_json.name}")
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ JSON
        try:
            with open(original_json, 'r', encoding='utf-8') as f:
                original_data = json.load(f)
            
            original_size = original_json.stat().st_size
            print(f"   –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {original_size / (1024*1024):.2f} MB")
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –æ—Ä–∏–≥–∏–Ω–∞–ª–∞: {e}")
            return False
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É
        if isinstance(original_data, list):
            conversations = original_data
        elif isinstance(original_data, dict):
            # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ —Å–ø–∏—Å–æ–∫ –¥–∏–∞–ª–æ–≥–æ–≤
            conversations = original_data.get('conversations', 
                           original_data.get('chats',
                           original_data.get('items', [])))
        else:
            print(f"‚ùå –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–Ω—ã—Ö: {type(original_data)}")
            return False
        
        print(f"   –ù–∞–π–¥–µ–Ω–æ –¥–∏–∞–ª–æ–≥–æ–≤: {len(conversations)}")
        
        # –ü–æ–¥—Å—á—ë—Ç —Å–æ–æ–±—â–µ–Ω–∏–π
        total_messages = 0
        total_content_size = 0
        
        for conv in conversations:
            # –ü–æ–¥—Å—á—ë—Ç —á–µ—Ä–µ–∑ mapping (ChatGPT —Ñ–æ—Ä–º–∞—Ç)
            if 'mapping' in conv:
                messages = conv['mapping']
                total_messages += len(messages)
                
                # –ü–æ–¥—Å—á—ë—Ç —Ä–∞–∑–º–µ—Ä–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
                for msg_id, msg_data in messages.items():
                    if isinstance(msg_data, dict) and 'message' in msg_data:
                        message = msg_data['message']
                        if message and 'content' in message:
                            content = message.get('content', {})
                            if isinstance(content, dict) and 'parts' in content:
                                for part in content['parts']:
                                    if isinstance(part, str):
                                        total_content_size += len(part)
            
            # –ü–æ–¥—Å—á—ë—Ç —á–µ—Ä–µ–∑ messages (–∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç)
            elif 'messages' in conv:
                messages = conv['messages']
                total_messages += len(messages)
                for msg in messages:
                    if isinstance(msg, dict) and 'content' in msg:
                        content = msg['content']
                        if isinstance(content, str):
                            total_content_size += len(content)
        
        print(f"   –í—Å–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏–π: {total_messages}")
        print(f"   –†–∞–∑–º–µ—Ä —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞: {total_content_size / (1024*1024):.2f} MB")
        
        self.report['original'] = {
            'file_size': original_size,
            'conversations': len(conversations),
            'messages': total_messages,
            'content_size': total_content_size
        }
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        print("\n" + "-"*70)
        print("–ü–†–û–í–ï–†–ö–ê –û–ë–†–ê–ë–û–¢–ê–ù–ù–´–• –§–ê–ô–õ–û–í")
        print("-"*70)
        
        individual_dir = self.processed_dir / 'chats' / 'individual'
        
        if not individual_dir.exists():
            print(f"‚ùå –ü–∞–ø–∫–∞ —Å –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–º–∏ —á–∞—Ç–∞–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {individual_dir}")
            return False
        
        # –ü–æ–¥—Å—á—ë—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        processed_files = list(individual_dir.glob('*.json'))
        print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤: {len(processed_files)}")
        
        processed_total_size = 0
        processed_messages = 0
        processed_content_size = 0
        
        for file in processed_files:
            file_size = file.stat().st_size
            processed_total_size += file_size
            
            try:
                with open(file, 'r', encoding='utf-8') as f:
                    conv = json.load(f)
                
                # –ü–æ–¥—Å—á—ë—Ç —Å–æ–æ–±—â–µ–Ω–∏–π
                if 'mapping' in conv:
                    messages = conv['mapping']
                    processed_messages += len(messages)
                    
                    for msg_id, msg_data in messages.items():
                        if isinstance(msg_data, dict) and 'message' in msg_data:
                            message = msg_data['message']
                            if message and 'content' in message:
                                content = message.get('content', {})
                                if isinstance(content, dict) and 'parts' in content:
                                    for part in content['parts']:
                                        if isinstance(part, str):
                                            processed_content_size += len(part)
                
                elif 'messages' in conv:
                    messages = conv['messages']
                    processed_messages += len(messages)
                    for msg in messages:
                        if isinstance(msg, dict) and 'content' in msg:
                            content = msg['content']
                            if isinstance(content, str):
                                processed_content_size += len(content)
                
            except Exception as e:
                print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è {file.name}: {e}")
        
        print(f"   –û–±—â–∏–π —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–æ–≤: {processed_total_size / (1024*1024):.2f} MB")
        print(f"   –í—Å–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏–π: {processed_messages}")
        print(f"   –†–∞–∑–º–µ—Ä —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞: {processed_content_size / (1024*1024):.2f} MB")
        
        self.report['processed'] = {
            'file_count': len(processed_files),
            'total_size': processed_total_size,
            'messages': processed_messages,
            'content_size': processed_content_size
        }
        
        # –°–†–ê–í–ù–ï–ù–ò–ï
        print("\n" + "="*70)
        print("–†–ï–ó–£–õ–¨–¢–ê–¢–´ –°–†–ê–í–ù–ï–ù–ò–Ø")
        print("="*70)
        
        conv_diff = self.report['original']['conversations'] - len(processed_files)
        msg_diff = self.report['original']['messages'] - processed_messages
        content_diff = self.report['original']['content_size'] - processed_content_size
        
        print(f"\nüìä –î–ò–ê–õ–û–ì–ò:")
        print(f"   –û—Ä–∏–≥–∏–Ω–∞–ª: {self.report['original']['conversations']}")
        print(f"   –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {len(processed_files)}")
        if conv_diff == 0:
            print(f"   ‚úÖ –†–∞–∑–Ω–∏—Ü–∞: 0 (–≤—Å—ë –æ–∫)")
        else:
            print(f"   ‚ùå –ü–û–¢–ï–†–Ø–ù–û: {conv_diff} –¥–∏–∞–ª–æ–≥–æ–≤")
        
        print(f"\nüì® –°–û–û–ë–©–ï–ù–ò–Ø:")
        print(f"   –û—Ä–∏–≥–∏–Ω–∞–ª: {self.report['original']['messages']}")
        print(f"   –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {processed_messages}")
        if msg_diff == 0:
            print(f"   ‚úÖ –†–∞–∑–Ω–∏—Ü–∞: 0 (–≤—Å—ë –æ–∫)")
        else:
            print(f"   ‚ùå –ü–û–¢–ï–†–Ø–ù–û: {msg_diff} —Å–æ–æ–±—â–µ–Ω–∏–π ({msg_diff/self.report['original']['messages']*100:.1f}%)")
        
        print(f"\nüíæ –¢–ï–ö–°–¢–û–í–´–ô –ö–û–ù–¢–ï–ù–¢:")
        print(f"   –û—Ä–∏–≥–∏–Ω–∞–ª: {self.report['original']['content_size'] / (1024*1024):.2f} MB")
        print(f"   –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {processed_content_size / (1024*1024):.2f} MB")
        if content_diff == 0:
            print(f"   ‚úÖ –†–∞–∑–Ω–∏—Ü–∞: 0 MB (–≤—Å—ë –æ–∫)")
        else:
            print(f"   ‚ùå –ü–û–¢–ï–†–Ø–ù–û: {content_diff / (1024*1024):.2f} MB ({content_diff/self.report['original']['content_size']*100:.1f}%)")
        
        print(f"\nüìÅ –†–ê–ó–ú–ï–† –§–ê–ô–õ–û–í:")
        print(f"   –û—Ä–∏–≥–∏–Ω–∞–ª JSON: {self.report['original']['file_size'] / (1024*1024):.2f} MB")
        print(f"   –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã: {processed_total_size / (1024*1024):.2f} MB")
        size_ratio = processed_total_size / self.report['original']['file_size']
        print(f"   –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ: {size_ratio:.2f}x")
        if size_ratio > 1.2:
            print(f"   ‚ÑπÔ∏è  –§–∞–π–ª—ã –±–æ–ª—å—à–µ –∏–∑-–∑–∞ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (indent=2)")
        elif size_ratio < 0.8:
            print(f"   ‚ö†Ô∏è  –§–ê–ô–õ–´ –ú–ï–ù–¨–®–ï - –≤–æ–∑–º–æ–∂–Ω–∞ –ø–æ—Ç–µ—Ä—è –¥–∞–Ω–Ω—ã—Ö")
        
        return True
    
    def check_html_file(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ HTML —Ñ–∞–π–ª–∞"""
        print("\n" + "="*70)
        print("–ü–†–û–í–ï–†–ö–ê HTML –§–ê–ô–õ–ê")
        print("="*70)
        
        # –ü–æ–∏—Å–∫ HTML —Ñ–∞–π–ª–∞ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª–µ
        html_files = list(self.original_dir.glob('**/*.html'))
        
        if not html_files:
            print("‚ÑπÔ∏è  HTML —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return True
        
        for html_file in html_files:
            print(f"\n‚úÖ –ù–∞–π–¥–µ–Ω: {html_file.name}")
            html_size = html_file.stat().st_size
            print(f"   –†–∞–∑–º–µ—Ä: {html_size / (1024*1024):.2f} MB")
            
            # –ß–∏—Ç–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ
            try:
                with open(html_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # –ë–∞–∑–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
                lines = content.count('\n')
                chars = len(content)
                
                print(f"   –°—Ç—Ä–æ–∫: {lines:,}")
                print(f"   –°–∏–º–≤–æ–ª–æ–≤: {chars:,}")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∏–∞–ª–æ–≥–æ–≤
                if 'conversation' in content.lower() or 'message' in content.lower():
                    print(f"   ‚ÑπÔ∏è  –°–æ–¥–µ—Ä–∂–∏—Ç –¥–∏–∞–ª–æ–≥–∏ - –º–æ–∂–Ω–æ —Ä–∞–∑–±–∏—Ç—å –Ω–∞ –±–ª–æ–∫–∏")
                
            except Exception as e:
                print(f"   ‚ö†Ô∏è  –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è: {e}")
        
        return True
    
    def generate_report(self):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç—á—ë—Ç"""
        print("\n" + "="*70)
        print("–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò")
        print("="*70)
        
        if not self.report.get('original') or not self.report.get('processed'):
            print("‚ö†Ô∏è  –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π")
            return
        
        orig = self.report['original']
        proc = self.report['processed']
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ—Ç–µ—Ä–∏
        msg_loss = (orig['messages'] - proc['messages']) / orig['messages'] * 100
        content_loss = (orig['content_size'] - proc['content_size']) / orig['content_size'] * 100
        
        if msg_loss > 5 or content_loss > 5:
            print("\n‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –ü–û–¢–ï–†–Ø –î–ê–ù–ù–´–• –û–ë–ù–ê–†–£–ñ–ï–ù–ê!")
            print("\n–ü—Ä–æ–±–ª–µ–º–∞:")
            print("   –°–∫—Ä–∏–ø—Ç ai_memory_core.py —Ç–µ—Ä—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ.")
            print(f"   –ü–æ—Ç–µ—Ä—è–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–π: {msg_loss:.1f}%")
            print(f"   –ü–æ—Ç–µ—Ä—è–Ω–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞: {content_loss:.1f}%")
            
            print("\n–í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã:")
            print("   1. –í–ª–æ–∂–µ–Ω–Ω—ã–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã mapping –Ω–µ –ø–æ–ª–Ω–æ—Å—Ç—å—é –∫–æ–ø–∏—Ä—É—é—Ç—Å—è")
            print("   2. –ë–∏–Ω–∞—Ä–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ base64) –æ–±—Ä–µ–∑–∞—é—Ç—Å—è")
            print("   3. –°–ø–µ—Ü—Å–∏–º–≤–æ–ª—ã/—ç–º–æ–¥–∑–∏ –ª–æ–º–∞—é—Ç –∫–æ–¥–∏—Ä–æ–≤–∫—É")
            
            print("\n–†–µ—à–µ–Ω–∏–µ:")
            print("   ‚úÖ –ù—É–∂–Ω–∞ –¥–æ—Ä–∞–±–æ—Ç–∫–∞ —Å–∫—Ä–∏–ø—Ç–∞ —Å –≥–ª—É–±–æ–∫–∏–º –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ–º")
            print("   ‚úÖ –î–æ–±–∞–≤–∏—Ç—å –≤–∞–ª–∏–¥–∞—Ü–∏—é –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–≥–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è")
            print("   ‚úÖ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å json.dumps –±–µ–∑ indent –¥–ª—è —Ç–æ—á–Ω–æ—Å—Ç–∏")
        
        elif msg_loss > 0 or content_loss > 0:
            print("\n‚ö†Ô∏è  –ù–µ–±–æ–ª—å—à–∞—è –ø–æ—Ç–µ—Ä—è –¥–∞–Ω–Ω—ã—Ö")
            print(f"   –ü–æ—Ç–µ—Ä—è–Ω–æ: {msg_loss:.2f}% —Å–æ–æ–±—â–µ–Ω–∏–π, {content_loss:.2f}% –∫–æ–Ω—Ç–µ–Ω—Ç–∞")
            print("   –í–æ–∑–º–æ–∂–Ω–æ, —ç—Ç–æ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∏–ª–∏ –ø—É—Å—Ç—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è")
        
        else:
            print("\n‚úÖ –î–ê–ù–ù–´–ï –°–û–•–†–ê–ù–ï–ù–´ –ü–û–õ–ù–û–°–¢–¨–Æ")
            print("   –í—Å–µ –¥–∏–∞–ª–æ–≥–∏ –∏ —Å–æ–æ–±—â–µ–Ω–∏—è –Ω–∞ –º–µ—Å—Ç–µ")
            print("   –†–∞–∑–Ω–∏—Ü–∞ –≤ —Ä–∞–∑–º–µ—Ä–µ —Ñ–∞–π–ª–æ–≤ –∏–∑-–∑–∞ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")


def main():
    parser = argparse.ArgumentParser(
        description='–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö',
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    
    parser.add_argument(
        '-o', '--original',
        required=True,
        help='–ü—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, temp/extracted)'
    )
    
    parser.add_argument(
        '-p', '--processed',
        required=True,
        help='–ü—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏'
    )
    
    args = parser.parse_args()
    
    checker = IntegrityChecker(args.original, args.processed)
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –ø—Ä–æ–≤–µ—Ä–∫–∏
    checker.check_json_conversations()
    checker.check_html_file()
    checker.generate_report()
    
    print("\n" + "="*70)
    print("–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
    print("="*70 + "\n")


if __name__ == '__main__':
    main()