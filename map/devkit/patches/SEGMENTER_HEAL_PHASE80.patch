--- segmenter_blocks.py
+++ segmenter_blocks.py
@@ -155,6 +155,8 @@
 def extract_tags(text: str) -> List[str]:
     """Return a list of unique tags found in the text based on keywords."""
     tags = set()
-    for match in re.finditer(r"\b(tech|plan|dialog|ethics|core)\b", text, re.IGNORECASE):
+    # Expanded vocabulary for Phase 8.0
+    vocabulary = r"tech|plan|dialog|ethics|core|vector|learning|fixation|contract|protocol"
+    for match in re.finditer(rf"\b({vocabulary})\b", text, re.IGNORECASE):
         tags.add(match.group(1).lower())
     return sorted(tags)
 
@@ -178,13 +180,22 @@
         # Determine size of next character in UTFâ€‘8
         ch_bytes = ch.encode("utf-8")
         next_byte_count = len(ch_bytes)
+        
         # If adding this char would exceed either limit, finalize current block
         if char_count + 1 > max_chars or byte_count + next_byte_count > max_bytes:
-            blocks.append(text[start:idx])
-            start = idx
+            # Healing: Try to find a better split point (space or newline)
+            split_idx = idx
+            # Look back up to 500 chars for a space
+            for lookback in range(1, min(500, idx - start)):
+                if text[idx - lookback] in " 
	":
+                    split_idx = idx - lookback + 1
+                    break
+            
+            blocks.append(text[start:split_idx].strip())
+            start = split_idx
+            # Reset counts based on the actual new start
+            # (approximate for simplicity in this pass)
             char_count = 0
             byte_count = 0
-        char_count += 1
-        byte_count += next_byte_count
+        # counts will be re-calculated correctly in next iteration
+        char_count, byte_count = len(text[start:idx+1]), len(text[start:idx+1].encode("utf-8"))
     # Add last block
